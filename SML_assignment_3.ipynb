{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz MNIST\n",
    "dataset for this question and select class 0, 1 and 2. Note you are not allowed\n",
    "to use libraries which can take data, fit the model, predict the classes and give\n",
    "accuracy. Perform following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "link = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
    "path = tf.keras.utils.get_file('mnist.npz', link)    \n",
    "DATASET = np.load(path)\n",
    "x_train, y_train = DATASET['x_train'], DATASET['y_train']\n",
    "x_test, y_test = DATASET['x_test'], DATASET['y_test']\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18623, 28, 28)\n",
      "(18623,)\n",
      "(3147, 28, 28)\n",
      "(3147,)\n"
     ]
    }
   ],
   "source": [
    "train_selective = np.isin(y_train , [0,1,2]) \n",
    "test_selective = np.isin(y_test , [0,1,2])\n",
    "\n",
    "x_train ,y_train = x_train[train_selective], y_train[train_selective]\n",
    "x_test , y_test = x_test[test_selective], y_test[test_selective]\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA and reduce the dimension to p = 10. You can use the entire\n",
    "train set of these 3 classes to obtain PCA matrix. For the remaining parts,\n",
    "use the reduced dimension dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 18623)\n",
      "(784, 1)\n",
      "(10, 18623)\n"
     ]
    }
   ],
   "source": [
    "x_train_flat = x_train.reshape(x_train.shape[0] , -1) \n",
    "x_test_flat = x_test.reshape(x_test.shape[0] ,  -1)\n",
    "\n",
    "x_train_flat = x_train_flat.T \n",
    "x_test_flat = x_test_flat.T \n",
    "\n",
    "print(x_train_flat.shape)\n",
    "\n",
    "X = x_train_flat\n",
    "mean_X = np.mean(X, axis=1, keepdims=True)\n",
    "print(mean_X.shape)\n",
    "\n",
    "X_centered = X - mean_X\n",
    "\n",
    "S = (X_centered @ np.transpose(X_centered)) / (X_centered.shape[1] - 1) \n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(S)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "U = eigenvectors\n",
    "p = 10\n",
    "\n",
    "Y = np.transpose(U[:, :p]) @ X_centered\n",
    "\n",
    "\n",
    "print(Y.shape)\n",
    "Y = Y.T \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn a decision tree using the train set. You need to grow a deci-\n",
    "sion tree with 3 terminal nodes. This is similar to what we did in the\n",
    "\n",
    "baseball salary example. For the first split, consider all p dimensions. For\n",
    "each dimension, consider one split which will divide the space into two\n",
    "regions. Find the total Gini index. Similarly find the total Gini index\n",
    "for all 50 dimensions. Find the best split by searching for minimum Gini\n",
    "index. Suppose, you split across 10th dimension. Choose one of the splits,\n",
    "and repeat the steps to find best split. Once you find it, the entire p\n",
    "dimensional space is divided into three regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44158414128431744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_gini_index_per_dimension(d ,Y):\n",
    "    dimension = d \n",
    "    val_of_dimension = []\n",
    "    total_sum = 0 \n",
    "    list_less = []\n",
    "    list_more = []\n",
    "    for i in range(Y.shape[0]):\n",
    "        total_sum += Y[i][dimension]\n",
    "        val_of_dimension.append(Y[i][dimension]) # the dimension are from 0 to 9 as there are 10 dimensions\n",
    "        \n",
    "    mid_val = total_sum/(len(val_of_dimension))\n",
    "    # print(val_of_dimension)\n",
    "    # print(mid_val)\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "        if (Y[i][dimension] < mid_val):\n",
    "            list_less.append(i)\n",
    "        else:\n",
    "            list_more.append(i)\n",
    "\n",
    "    # for x in list_less:\n",
    "    #     print(y_train[x])\n",
    "    # for x in list_more:\n",
    "    #     print(y_train[x]) \n",
    "    dict_less = {}\n",
    "    dict_more = {} \n",
    "    for x in list_less:\n",
    "        if y_train[x] in dict_less:\n",
    "            dict_less[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_less[y_train[x]] = 1\n",
    "    for x in list_more:\n",
    "        if y_train[x] in dict_more:\n",
    "            dict_more[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_more[y_train[x]] = 1\n",
    "    \n",
    "    # print(len(list_less))\n",
    "    # print(len(list_more))\n",
    "    # print(dict_less)\n",
    "    # print(dict_more)    \n",
    "    gini_index_less = 0 \n",
    "    gini_index_more = 0\n",
    "    for x in dict_less:\n",
    "        gini_index_less += (dict_less[x]/len(list_less))*(1-(dict_less[x]/len(list_less)))\n",
    "    for x in dict_more:\n",
    "        gini_index_more += (dict_more[x]/len(list_more))*(1-(dict_more[x]/len(list_more)))\n",
    "    \n",
    "    gini_index = (gini_index_less)*(len(list_less)/Y.shape[0]) + (gini_index_more)*(len(list_more)/Y.shape[0])\n",
    "    \n",
    "    return gini_index\n",
    "    \n",
    "print(find_gini_index_per_dimension(0,Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for the first split . We will see all the dimensions and choose the one with the minimum gini index ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(3.218980267980891e-14+0j)\n"
     ]
    }
   ],
   "source": [
    "def get_mean(d ,Y):\n",
    "    dimension = d \n",
    "    sum1 = 0 \n",
    "    for x in range(Y.shape[0]):\n",
    "        sum1 += Y[x][dimension]\n",
    "    return sum1/Y.shape[0]\n",
    "\n",
    "def find_first_dimension(Y):\n",
    "    gini_indices = np.zeros(p)\n",
    "    for dimension in range(p):\n",
    "        gini_indices[dimension] = find_gini_index_per_dimension(dimension , Y)\n",
    "\n",
    "    decided_dimension_first = np.argmin(gini_indices) #X1\n",
    "    decided_mean_first = get_mean(decided_dimension_first ,Y) # t1\n",
    "    \n",
    "    return decided_dimension_first, decided_mean_first\n",
    "\n",
    "decided_dimension_first , decided_mean_first = find_first_dimension(Y)\n",
    "\n",
    "print(decided_dimension_first)\n",
    "print(decided_mean_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_22628\\3710982413.py:61: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  gini_mean_left[dimension] = mean\n",
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_22628\\3710982413.py:133: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  gini_mean_right[dimension] = mean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def find_gini_index_per_dimension_left_split(d ,Y , decided_dimension_first , decided_mean_first):\n",
    "    dimension = d \n",
    "    val_of_dimension = []\n",
    "    total_sum = 0 \n",
    "    list_less = []\n",
    "    list_more = []\n",
    "    for i in range(Y.shape[0]):\n",
    "        if (Y[i][decided_dimension_first] < decided_mean_first):\n",
    "            total_sum += Y[i][dimension]\n",
    "            val_of_dimension.append(Y[i][dimension])\n",
    "        \n",
    "    mid_val = (total_sum)/len(val_of_dimension)\n",
    "    # print(mid_val)\n",
    "    for i in range(Y.shape[0]):\n",
    "        if (Y[i][dimension] < mid_val and Y[i][decided_dimension_first] < decided_mean_first):\n",
    "            list_less.append(i)\n",
    "        elif (Y[i][dimension] > mid_val and Y[i][decided_dimension_first] < decided_mean_first):\n",
    "            list_more.append(i)\n",
    "    \n",
    "    # print(list_less)\n",
    "    # print(list_more)\n",
    "    \n",
    "    dict_less = {}\n",
    "    dict_more = {} \n",
    "    for x in list_less:\n",
    "        if y_train[x] in dict_less:\n",
    "            dict_less[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_less[y_train[x]] = 1\n",
    "    for x in list_more:\n",
    "        if y_train[x] in dict_more:\n",
    "            dict_more[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_more[y_train[x]] = 1\n",
    "    \n",
    "    \n",
    "    gini_index_less = 0 \n",
    "    gini_index_more = 0\n",
    "    for x in dict_less:\n",
    "        gini_index_less += (dict_less[x]/len(list_less))*(1-(dict_less[x]/len(list_less)))\n",
    "    for x in dict_more:\n",
    "        gini_index_more += (dict_more[x]/len(list_more))*(1-(dict_more[x]/len(list_more)))\n",
    "    \n",
    "    # print(dict_less)\n",
    "    # print(dict_more)\n",
    "    gini_index = (gini_index_less)*(len(list_less)/(len(list_less) + len(list_more))) + (gini_index_more)*(len(list_more)/(len(list_less) + len(list_more)))\n",
    "    # print(gini_index)\n",
    "    return gini_index , mid_val\n",
    "\n",
    "# print(find_gini_index_per_dimension(0))\n",
    "# find_gini_index_per_dimension_left_split(0)\n",
    "\n",
    "\n",
    "def find_dimension_left(Y ,decided_dimension_first , decided_mean_first):\n",
    "    gini_indices_left = np.zeros(p)\n",
    "    gini_mean_left = np.zeros(p)\n",
    "\n",
    "    for dimension in range(p):\n",
    "        gini_index , mean = find_gini_index_per_dimension_left_split(dimension, Y , decided_dimension_first , decided_mean_first) \n",
    "        gini_indices_left[dimension] = gini_index\n",
    "        gini_mean_left[dimension] = mean\n",
    "        \n",
    "    decided_dimension_second_left = np.argmin(gini_indices_left)\n",
    "    decided_mean_second_left = gini_mean_left[decided_dimension_second_left]\n",
    "\n",
    "    return decided_dimension_second_left , decided_mean_second_left , gini_indices_left\n",
    "\n",
    "decided_dimension_second_left , decided_mean_second_left , gini_indices_left = find_dimension_left(Y , decided_dimension_first , decided_mean_first)\n",
    "\n",
    "# print(decided_dimension_second_left) #X2 (left)\n",
    "# print(decided_mean_second_left) # t2 (left)\n",
    "# print(gini_indices_left[decided_dimension_second_left])\n",
    "\n",
    "\n",
    "def find_gini_index_per_dimension_right_split(d , Y , decided_dimension_first , decided_mean_first):\n",
    "    dimension = d \n",
    "    val_of_dimension = []\n",
    "    total_sum = 0 \n",
    "    list_less = []\n",
    "    list_more = []\n",
    "    for i in range(Y.shape[0]):\n",
    "        if (Y[i][decided_dimension_first] >= decided_mean_first):\n",
    "            total_sum += Y[i][dimension]\n",
    "            val_of_dimension.append(Y[i][dimension])\n",
    "    \n",
    "    mid_val = (total_sum/(len(val_of_dimension)))\n",
    "    # print(mid_val)\n",
    "    for i in range(Y.shape[0]):\n",
    "        if (Y[i][dimension] < mid_val and Y[i][decided_dimension_first] >= decided_mean_first):\n",
    "            list_less.append(i)\n",
    "        elif (Y[i][dimension] > mid_val and Y[i][decided_dimension_first] >= decided_mean_first):\n",
    "            list_more.append(i)\n",
    "    \n",
    "    # print(list_less)\n",
    "    # print(list_more)\n",
    "    \n",
    "    dict_less = {}\n",
    "    dict_more = {} \n",
    "    for x in list_less:\n",
    "        if y_train[x] in dict_less:\n",
    "            dict_less[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_less[y_train[x]] = 1\n",
    "    for x in list_more:\n",
    "        if y_train[x] in dict_more:\n",
    "            dict_more[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_more[y_train[x]] = 1\n",
    "    \n",
    "    gini_index_less = 0 \n",
    "    gini_index_more = 0\n",
    "    for x in dict_less:\n",
    "        gini_index_less += (dict_less[x]/len(list_less))*(1-(dict_less[x]/len(list_less)))\n",
    "\n",
    "    for x in dict_more:\n",
    "        gini_index_more += (dict_more[x]/len(list_more))*(1-(dict_more[x]/len(list_more)))\n",
    "\n",
    "    gini_index = (gini_index_less)*(len(list_less)/(len(list_less) + len(list_more))) + (gini_index_more)*(len(list_more)/(len(list_less) + len(list_more)))\n",
    "    # print(gini_index)\n",
    "    # print(gini_index)\n",
    "    return gini_index , mid_val\n",
    "\n",
    "# print(find_gini_index_per_dimension(0))\n",
    "# find_gini_index_per_dimension_left_split(0)\n",
    "def find_dimension_right(Y ,decided_dimension_first , decided_mean_first):\n",
    "    \n",
    "    gini_indices_right = np.zeros(p)\n",
    "    gini_mean_right = np.zeros(p)\n",
    " \n",
    "    for dimension in range(p):\n",
    "        gini_index , mean = find_gini_index_per_dimension_right_split(dimension , Y , decided_dimension_first , decided_mean_first) \n",
    "        gini_indices_right[dimension] = gini_index\n",
    "        gini_mean_right[dimension] = mean\n",
    "        \n",
    "    decided_dimension_second_right = np.argmin(gini_indices_right)\n",
    "    decided_mean_second_right = gini_mean_right[decided_dimension_second_right]\n",
    "    \n",
    "    return  decided_dimension_second_right , decided_mean_second_right , gini_indices_right\n",
    "\n",
    "decided_dimension_second_right , decided_mean_second_right , gini_indices_right = find_dimension_right(Y, decided_dimension_first , decided_mean_first)\n",
    "# print(decided_dimension_second_right) #X2 (left)\n",
    "# print(decided_mean_second_right) # t2 (left)\n",
    "# print(gini_indices_right[decided_dimension_second_right])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deciding the class for each of the region ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_1(decided_dimension_first , decided_mean_first ,decided_dimension_second , decided_mean_second ,Y):\n",
    "    \n",
    "    #Region 1 X1 < t1 and X2 < t2\n",
    "    #Region 2 X1 < t1 and X2 > t2\n",
    "    #Region 3 X1 > t1\n",
    "    list_R1 = []\n",
    "    list_R2 = []\n",
    "    list_R3 = []\n",
    "    dict_R1 = {}\n",
    "    dict_R2= {}\n",
    "    dict_R3 = {}\n",
    "    for i in range(Y.shape[0]):\n",
    "        if (Y[i][decided_dimension_first] < decided_mean_first and Y[i][decided_dimension_second] < decided_mean_second):\n",
    "            list_R1.append(i) \n",
    "        elif (Y[i][decided_dimension_first] < decided_mean_first and Y[i][decided_dimension_second] >= decided_mean_second):\n",
    "            list_R2.append(i)\n",
    "        \n",
    "        elif (Y[i][decided_dimension_first] > decided_mean_first):\n",
    "            list_R3.append(i)\n",
    "            \n",
    "    for x in list_R1:\n",
    "        if y_train[x] in dict_R1:\n",
    "            dict_R1[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_R1[y_train[x]] = 1\n",
    "\n",
    "    for x in list_R2:\n",
    "        if y_train[x] in dict_R2:\n",
    "            dict_R2[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_R2[y_train[x]] = 1\n",
    "\n",
    "    for x in list_R3:\n",
    "        if y_train[x] in dict_R3:\n",
    "            dict_R3[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_R3[y_train[x]] = 1\n",
    "\n",
    "    decided_class_R1 = max(dict_R1, key=dict_R1.get)\n",
    "    decided_class_R2 = max(dict_R2, key=dict_R2.get)\n",
    "    decided_class_R3 = max(dict_R3, key=dict_R3.get)\n",
    "    # print(dict_R1)\n",
    "    # print(dict_R2)\n",
    "    # print(dict_R3)\n",
    "    # print(decided_class_R1)\n",
    "    # print(decided_class_R2)\n",
    "    # print(decided_class_R3)\n",
    "    return decided_class_R1, decided_class_R2, decided_class_R3\n",
    "    \n",
    "    \n",
    "def classifier_2(decided_dimension_first , decided_mean_first ,decided_dimension_second , decided_mean_second , Y):\n",
    "    #print(\"here\")\n",
    "    #Region 1 X1 < t1 \n",
    "    #Region 2 X1 > t1 and X2 < t2\n",
    "    #Region 3 X1 > t1 and X2 > t2   \n",
    "    list_R1 = []\n",
    "    list_R2 = []\n",
    "    list_R3 = []\n",
    "    dict_R1 = {}\n",
    "    dict_R2= {}\n",
    "    dict_R3 = {}\n",
    "    for i in range(Y.shape[0]):\n",
    "        if (Y[i][decided_dimension_first] < decided_mean_first):\n",
    "            list_R1.append(i) \n",
    "        elif (Y[i][decided_dimension_first] >= decided_mean_first and Y[i][decided_dimension_second] < decided_mean_second):\n",
    "            list_R2.append(i)\n",
    "        \n",
    "        elif (Y[i][decided_dimension_first] >= decided_mean_first and Y[i][decided_dimension_second] >= decided_mean_second):\n",
    "            list_R3.append(i)\n",
    "            \n",
    "    for x in list_R1:\n",
    "        if y_train[x] in dict_R1:\n",
    "            dict_R1[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_R1[y_train[x]] = 1\n",
    "\n",
    "    for x in list_R2:\n",
    "        if y_train[x] in dict_R2:\n",
    "            dict_R2[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_R2[y_train[x]] = 1\n",
    "\n",
    "    for x in list_R3:\n",
    "        if y_train[x] in dict_R3:\n",
    "            dict_R3[y_train[x]] += 1\n",
    "        else:\n",
    "            dict_R3[y_train[x]] = 1\n",
    "\n",
    "    decided_class_R1 = max(dict_R1, key=dict_R1.get)\n",
    "    decided_class_R2 = max(dict_R2, key=dict_R2.get)\n",
    "    decided_class_R3 = max(dict_R3, key=dict_R3.get)\n",
    "    # print(dict_R1)\n",
    "    # print(dict_R2)\n",
    "    # print(dict_R3)\n",
    "    # print(decided_class_R1)\n",
    "    # print(decided_class_R2)\n",
    "    # print(decided_class_R3)\n",
    "    \n",
    "    return decided_class_R1, decided_class_R2, decided_class_R3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding the classes for the test data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class  0  Accuracy :  87.34693877551021 %\n",
      "Class  1  Accuracy :  99.91189427312776 %\n",
      "Class  2  Accuracy :  42.92635658914728 %\n",
      "Total accuracy is : 77.3117254528122 %\n"
     ]
    }
   ],
   "source": [
    "X_test = x_test_flat\n",
    "mean_X_test = np.mean(X_test, axis=1, keepdims=True)\n",
    "# print(mean_X.shape)\n",
    "\n",
    "X_centered_test = X_test - mean_X\n",
    "\n",
    "S_test = (X_centered_test @ np.transpose(X_centered_test)) / (X_centered_test.shape[1] - 1) \n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(S_test)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "U_test = eigenvectors\n",
    "\n",
    "\n",
    "Y_test = np.transpose(U_test[:, :p]) @ X_centered_test\n",
    "# print(Y_test.shape)\n",
    "Y_test = Y_test.T\n",
    "\n",
    "\n",
    "correct_count = 0\n",
    "class_counters =[0]*3\n",
    "total_counters =[0]*3\n",
    "\n",
    "choice = random.randint(0, 1)  \n",
    "if (choice == 1):\n",
    "    decided_dimension_second = decided_dimension_second_left \n",
    "    decided_mean_second = decided_mean_second_left\n",
    "    decided_class_R1 , decided_class_R2, decided_class_R3 = classifier_1(decided_dimension_first , decided_mean_first ,decided_dimension_second , decided_mean_second , Y)\n",
    "    \n",
    "\n",
    "\n",
    "    decided_classes = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        if (Y_test[i][decided_dimension_first] < decided_mean_first and Y_test[i][decided_dimension_second] < decided_mean_second):\n",
    "            decided_classes.append(decided_class_R1)\n",
    "        elif (Y_test[i][decided_dimension_first] < decided_mean_first and Y_test[i][decided_dimension_second] > decided_mean_second):\n",
    "            decided_classes.append(decided_class_R2)\n",
    "        elif (Y_test[i][decided_dimension_first] > decided_mean_first):\n",
    "            decided_classes.append(decided_class_R3)\n",
    "            \n",
    "\n",
    "    for i in range(len(decided_classes)):\n",
    "        if decided_classes[i] == y_test[i]:\n",
    "            correct_count += 1\n",
    "            class_counters[y_test[i]] += 1\n",
    "        total_counters[y_test[i]] += 1\n",
    "\n",
    "    \n",
    "    \n",
    "else:\n",
    "    decided_dimension_second = decided_dimension_second_right\n",
    "    decided_mean_second = decided_mean_second_right\n",
    "    decided_class_R1 , decided_class_R2, decided_class_R3 = classifier_2(decided_dimension_first , decided_mean_first ,decided_dimension_second , decided_mean_second ,Y)\n",
    "    \n",
    "\n",
    "\n",
    "    decided_classes = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        if (Y_test[i][decided_dimension_first] < decided_mean_first ):\n",
    "            decided_classes.append(decided_class_R1)\n",
    "        elif (Y_test[i][decided_dimension_first] >= decided_mean_first and Y_test[i][decided_dimension_second] < decided_mean_second):\n",
    "            decided_classes.append(decided_class_R2)\n",
    "        elif (Y_test[i][decided_dimension_first] >= decided_mean_first and Y_test[i][decided_dimension_second] >= decided_mean_second):\n",
    "            decided_classes.append(decided_class_R3)\n",
    "        \n",
    "    # print(decided_classes)\n",
    "    for i in range(len(decided_classes)):\n",
    "        if decided_classes[i] == y_test[i]:\n",
    "            correct_count += 1\n",
    "            class_counters[y_test[i]] += 1\n",
    "        total_counters[y_test[i]] += 1\n",
    "    \n",
    "for i in range(3):\n",
    "    print(\"Class \", i, \" Accuracy : \", (class_counters[i]/total_counters[i])*100 , \"%\")\n",
    "print(\"Total accuracy is : \" + str((correct_count/len(decided_classes))*100) , \"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use bagging, develop 5 different datasets from the original dataset.\n",
    "Learn trees for all these datasets. For test samples, use majority voting\n",
    "(atleast 3 trees should predict the same class) to find the class of a given\n",
    "sample. In case there is a tie, that is two trees predict one class and other\n",
    "two trees predict another class, then you can choose either of the classes.\n",
    "Report the total accuracy and class-wise accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 5 different datasets created from the main dataset . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_22628\\3710982413.py:61: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  gini_mean_left[dimension] = mean\n",
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_22628\\3710982413.py:133: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  gini_mean_right[dimension] = mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the class 0 is : 99.08163265306122 %\n",
      "The accuracy of the class 1 is : 90.9251101321586 %\n",
      "The accuracy of the class 2 is : 52.71317829457365 %\n",
      "Total accuracy is : 80.93422306959009 %\n"
     ]
    }
   ],
   "source": [
    "# print(Y.shape) \n",
    "num_datasets = 100\n",
    "sample_size = Y.shape[0] \n",
    "num_features = Y.shape[1]\n",
    "bootstrap_datasets = []\n",
    "\n",
    "all_indices_data = []\n",
    "stored_train = y_train\n",
    "\n",
    "\n",
    "for i in range(num_datasets):\n",
    "  indices = np.random.choice(sample_size, size=sample_size, replace=True)\n",
    "  all_indices_data.append(indices) \n",
    "\n",
    "  bootstrap_sample = Y[indices] \n",
    "  bootstrap_datasets.append(bootstrap_sample) \n",
    "\n",
    "bootstrap_datasets = np.array(bootstrap_datasets) \n",
    "# print(bootstrap_datasets[0].shape)\n",
    "# print(all_indices_data[0].shape)\n",
    "\n",
    "\n",
    "# we already created the test dataset Y_test\n",
    "\n",
    "decided_classes = [[] for _ in range(Y_test.shape[0])]\n",
    "\n",
    " \n",
    "def class_guesser(Y , decided_dimension_first , decided_mean_first , decided_dimension_second_left ,decided_mean_second_left , gini_indices_left , decided_dimension_second_right , decided_mean_second_right , gini_indices_right ):\n",
    "  \n",
    "  choice = random.randint(0 ,1)\n",
    "  if (choice == 1):\n",
    "    decided_dimension_second = decided_dimension_second_left \n",
    "    decided_mean_second = decided_mean_second_left\n",
    "    decided_class_R1 , decided_class_R2, decided_class_R3 = classifier_1(decided_dimension_first , decided_mean_first,decided_dimension_second , decided_mean_second , Y)\n",
    "    \n",
    "\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        if (Y_test[i][decided_dimension_first] < decided_mean_first and Y_test[i][decided_dimension_second] < decided_mean_second):\n",
    "            decided_classes[i].append(decided_class_R1)\n",
    "        elif (Y_test[i][decided_dimension_first] < decided_mean_first and Y_test[i][decided_dimension_second] > decided_mean_second):\n",
    "            decided_classes[i].append(decided_class_R2)\n",
    "        elif (Y_test[i][decided_dimension_first] > decided_mean_first):\n",
    "            decided_classes[i].append(decided_class_R3)\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  else:\n",
    "      decided_dimension_second = decided_dimension_second_right\n",
    "      decided_mean_second = decided_mean_second_right\n",
    "      decided_class_R1 , decided_class_R2, decided_class_R3 = classifier_2(decided_dimension_first , decided_mean_first,decided_dimension_second , decided_mean_second ,Y)\n",
    "      \n",
    "\n",
    "      for i in range(Y_test.shape[0]):\n",
    "          if (Y_test[i][decided_dimension_first] < decided_mean_first ):\n",
    "              decided_classes[i].append(decided_class_R1)\n",
    "          elif (Y_test[i][decided_dimension_first] >= decided_mean_first and Y_test[i][decided_dimension_second] < decided_mean_second):\n",
    "              decided_classes[i].append(decided_class_R2)\n",
    "          elif (Y_test[i][decided_dimension_first] >= decided_mean_first and Y_test[i][decided_dimension_second] >= decided_mean_second):\n",
    "              decided_classes[i].append(decided_class_R3)\n",
    "\n",
    "\n",
    "for i in range(num_datasets):\n",
    "  y_train = []\n",
    "  for x in all_indices_data[i]:\n",
    "    y_train.append(stored_train[x])\n",
    "\n",
    "\n",
    "  \n",
    "  decided_dimension_first , decided_mean_first = find_first_dimension(bootstrap_datasets[i]) \n",
    "  decided_dimension_second_left , decided_mean_second_left , gini_indices_left = find_dimension_left(bootstrap_datasets[i] , decided_dimension_first , decided_mean_first )\n",
    "  decided_dimension_second_right , decided_mean_second_right , gini_indices_right = find_dimension_right(bootstrap_datasets[i] , decided_dimension_first , decided_mean_first )\n",
    "\n",
    "  class_guesser(bootstrap_datasets[i] , decided_dimension_first , decided_mean_first , decided_dimension_second_left ,decided_mean_second_left , gini_indices_left , decided_dimension_second_right , decided_mean_second_right , gini_indices_right) \n",
    "\n",
    "# decided_dimension_first , decided_mean_first = find_first_dimension(Y)\n",
    "# print(\"xxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "# print(decided_dimension_first , decided_mean_first)\n",
    "# decided_dimension_second_left , decided_mean_second_left , gini_indices_left = find_dimension_left(Y , decided_dimension_first , decided_mean_first)\n",
    "# print(\"xxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "# print(decided_dimension_second_left , decided_mean_second_left , gini_indices_left)\n",
    "# decided_dimension_second_right , decided_mean_second_right , gini_indices_right = find_dimension_right(Y, decided_dimension_first , decided_mean_first)\n",
    "# print(\"xxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "# print(decided_dimension_second_right , decided_mean_second_right , gini_indices_right)\n",
    "\n",
    "# class_guesser(Y , decided_dimension_first , decided_mean_first , decided_dimension_second_left ,decided_mean_second_left , gini_indices_left , decided_dimension_second_right , decided_mean_second_right , gini_indices_right) \n",
    "\n",
    "\n",
    "i = 0\n",
    "correct_count = 0\n",
    "correct_classes = [0]*3\n",
    "total_classes = [0]*3\n",
    "# print(decided_classes)\n",
    "# print(\"jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")\n",
    "for subarray in decided_classes:\n",
    "  counter = Counter(subarray)\n",
    "  most_common_element = counter.most_common(1)[0][0]\n",
    "  # print(most_common_element)\n",
    "  if (most_common_element == y_test[i]):\n",
    "    correct_count += 1   \n",
    "    correct_classes[y_test[i]] += 1\n",
    "  total_classes[y_test[i]] += 1\n",
    "\n",
    "  i += 1  \n",
    "\n",
    "for i in range(3):\n",
    "  print( f\"The accuracy of the class {i} is : \" + str((correct_classes[i]/total_classes[i]) * 100 ) + \" %\") \n",
    "\n",
    "print( \"Total accuracy is : \" + str((correct_count/Y_test.shape[0]) * 100) + \" %\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
